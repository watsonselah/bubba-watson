{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JA864k2XM9w"
      },
      "source": [
        "# Question 4.1: PySpark Random Forest Implementation\n",
        "\n",
        "This notebook ports the pandas Random Forest implementation to PySpark, using only PySpark APIs for data processing and MLlib for machine learning.\n",
        "\n",
        "## Overview\n",
        "- Load data from Google Cloud Storage\n",
        "- Join datasets using PySpark DataFrame operations\n",
        "- Perform feature engineering with PySpark\n",
        "- Train Random Forest using PySpark MLlib\n",
        "- Evaluate model and save to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DLPiTsdVXM9x"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, Imputer, StandardScaler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PLkdLTBRXM9y",
        "outputId": "1cdfdde2-cadf-47bf-b9fa-0f9301aaf0ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.5.1\n",
            "Spark context: <SparkContext master=local[*] appName=RandomForestPySpark>\n"
          ]
        }
      ],
      "source": [
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"RandomForestPySpark\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(f\"Spark version: {spark.version}\")\n",
        "print(f\"Spark context: {spark.sparkContext}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KhvUgzjXM9z"
      },
      "source": [
        "## Data Loading\n",
        "Load the same datasets from Google Cloud Storage as in the original implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GsR1IPhbXM9z",
        "outputId": "8ff846d6-820f-4a74-9278-44e4d7970c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data files downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download data files (same as original implementation)\n",
        "import subprocess\n",
        "\n",
        "# Download external sources\n",
        "subprocess.run([\n",
        "    \"wget\",\n",
        "    \"https://storage.googleapis.com/bdt-spark-store/external_sources.csv\",\n",
        "    \"-O\", \"gcs_external_sources.csv\"\n",
        "], check=True)\n",
        "\n",
        "# Download internal data\n",
        "subprocess.run([\n",
        "    \"wget\",\n",
        "    \"https://storage.googleapis.com/bdt-spark-store/internal_data.csv\",\n",
        "    \"-O\", \"gcs_internal_data.csv\"\n",
        "], check=True)\n",
        "\n",
        "print(\"Data files downloaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VJX9f6gIXM9z",
        "outputId": "5e0db73b-e9ba-4fd0-896a-372f5e548f5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Internal data shape: 307511 rows, 119 columns\n",
            "External data shape: 307511 rows, 4 columns\n",
            "\n",
            "Internal data schema:\n",
            "root\n",
            " |-- SK_ID_CURR: integer (nullable = true)\n",
            " |-- TARGET: integer (nullable = true)\n",
            " |-- NAME_CONTRACT_TYPE: string (nullable = true)\n",
            " |-- CODE_GENDER: string (nullable = true)\n",
            " |-- FLAG_OWN_CAR: string (nullable = true)\n",
            " |-- FLAG_OWN_REALTY: string (nullable = true)\n",
            " |-- CNT_CHILDREN: integer (nullable = true)\n",
            " |-- AMT_INCOME_TOTAL: double (nullable = true)\n",
            " |-- AMT_CREDIT: double (nullable = true)\n",
            " |-- AMT_ANNUITY: double (nullable = true)\n",
            " |-- AMT_GOODS_PRICE: double (nullable = true)\n",
            " |-- NAME_TYPE_SUITE: string (nullable = true)\n",
            " |-- NAME_INCOME_TYPE: string (nullable = true)\n",
            " |-- NAME_EDUCATION_TYPE: string (nullable = true)\n",
            " |-- NAME_FAMILY_STATUS: string (nullable = true)\n",
            " |-- NAME_HOUSING_TYPE: string (nullable = true)\n",
            " |-- REGION_POPULATION_RELATIVE: double (nullable = true)\n",
            " |-- DAYS_BIRTH: integer (nullable = true)\n",
            " |-- DAYS_EMPLOYED: integer (nullable = true)\n",
            " |-- DAYS_REGISTRATION: double (nullable = true)\n",
            " |-- DAYS_ID_PUBLISH: integer (nullable = true)\n",
            " |-- OWN_CAR_AGE: double (nullable = true)\n",
            " |-- FLAG_MOBIL: integer (nullable = true)\n",
            " |-- FLAG_EMP_PHONE: integer (nullable = true)\n",
            " |-- FLAG_WORK_PHONE: integer (nullable = true)\n",
            " |-- FLAG_CONT_MOBILE: integer (nullable = true)\n",
            " |-- FLAG_PHONE: integer (nullable = true)\n",
            " |-- FLAG_EMAIL: integer (nullable = true)\n",
            " |-- OCCUPATION_TYPE: string (nullable = true)\n",
            " |-- CNT_FAM_MEMBERS: double (nullable = true)\n",
            " |-- REGION_RATING_CLIENT: integer (nullable = true)\n",
            " |-- REGION_RATING_CLIENT_W_CITY: integer (nullable = true)\n",
            " |-- WEEKDAY_APPR_PROCESS_START: string (nullable = true)\n",
            " |-- HOUR_APPR_PROCESS_START: integer (nullable = true)\n",
            " |-- REG_REGION_NOT_LIVE_REGION: integer (nullable = true)\n",
            " |-- REG_REGION_NOT_WORK_REGION: integer (nullable = true)\n",
            " |-- LIVE_REGION_NOT_WORK_REGION: integer (nullable = true)\n",
            " |-- REG_CITY_NOT_LIVE_CITY: integer (nullable = true)\n",
            " |-- REG_CITY_NOT_WORK_CITY: integer (nullable = true)\n",
            " |-- LIVE_CITY_NOT_WORK_CITY: integer (nullable = true)\n",
            " |-- ORGANIZATION_TYPE: string (nullable = true)\n",
            " |-- APARTMENTS_AVG: double (nullable = true)\n",
            " |-- BASEMENTAREA_AVG: double (nullable = true)\n",
            " |-- YEARS_BEGINEXPLUATATION_AVG: double (nullable = true)\n",
            " |-- YEARS_BUILD_AVG: double (nullable = true)\n",
            " |-- COMMONAREA_AVG: double (nullable = true)\n",
            " |-- ELEVATORS_AVG: double (nullable = true)\n",
            " |-- ENTRANCES_AVG: double (nullable = true)\n",
            " |-- FLOORSMAX_AVG: double (nullable = true)\n",
            " |-- FLOORSMIN_AVG: double (nullable = true)\n",
            " |-- LANDAREA_AVG: double (nullable = true)\n",
            " |-- LIVINGAPARTMENTS_AVG: double (nullable = true)\n",
            " |-- LIVINGAREA_AVG: double (nullable = true)\n",
            " |-- NONLIVINGAPARTMENTS_AVG: double (nullable = true)\n",
            " |-- NONLIVINGAREA_AVG: double (nullable = true)\n",
            " |-- APARTMENTS_MODE: double (nullable = true)\n",
            " |-- BASEMENTAREA_MODE: double (nullable = true)\n",
            " |-- YEARS_BEGINEXPLUATATION_MODE: double (nullable = true)\n",
            " |-- YEARS_BUILD_MODE: double (nullable = true)\n",
            " |-- COMMONAREA_MODE: double (nullable = true)\n",
            " |-- ELEVATORS_MODE: double (nullable = true)\n",
            " |-- ENTRANCES_MODE: double (nullable = true)\n",
            " |-- FLOORSMAX_MODE: double (nullable = true)\n",
            " |-- FLOORSMIN_MODE: double (nullable = true)\n",
            " |-- LANDAREA_MODE: double (nullable = true)\n",
            " |-- LIVINGAPARTMENTS_MODE: double (nullable = true)\n",
            " |-- LIVINGAREA_MODE: double (nullable = true)\n",
            " |-- NONLIVINGAPARTMENTS_MODE: double (nullable = true)\n",
            " |-- NONLIVINGAREA_MODE: double (nullable = true)\n",
            " |-- APARTMENTS_MEDI: double (nullable = true)\n",
            " |-- BASEMENTAREA_MEDI: double (nullable = true)\n",
            " |-- YEARS_BEGINEXPLUATATION_MEDI: double (nullable = true)\n",
            " |-- YEARS_BUILD_MEDI: double (nullable = true)\n",
            " |-- COMMONAREA_MEDI: double (nullable = true)\n",
            " |-- ELEVATORS_MEDI: double (nullable = true)\n",
            " |-- ENTRANCES_MEDI: double (nullable = true)\n",
            " |-- FLOORSMAX_MEDI: double (nullable = true)\n",
            " |-- FLOORSMIN_MEDI: double (nullable = true)\n",
            " |-- LANDAREA_MEDI: double (nullable = true)\n",
            " |-- LIVINGAPARTMENTS_MEDI: double (nullable = true)\n",
            " |-- LIVINGAREA_MEDI: double (nullable = true)\n",
            " |-- NONLIVINGAPARTMENTS_MEDI: double (nullable = true)\n",
            " |-- NONLIVINGAREA_MEDI: double (nullable = true)\n",
            " |-- FONDKAPREMONT_MODE: string (nullable = true)\n",
            " |-- HOUSETYPE_MODE: string (nullable = true)\n",
            " |-- TOTALAREA_MODE: double (nullable = true)\n",
            " |-- WALLSMATERIAL_MODE: string (nullable = true)\n",
            " |-- EMERGENCYSTATE_MODE: string (nullable = true)\n",
            " |-- OBS_30_CNT_SOCIAL_CIRCLE: double (nullable = true)\n",
            " |-- DEF_30_CNT_SOCIAL_CIRCLE: double (nullable = true)\n",
            " |-- OBS_60_CNT_SOCIAL_CIRCLE: double (nullable = true)\n",
            " |-- DEF_60_CNT_SOCIAL_CIRCLE: double (nullable = true)\n",
            " |-- DAYS_LAST_PHONE_CHANGE: double (nullable = true)\n",
            " |-- FLAG_DOCUMENT_2: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_3: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_4: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_5: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_6: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_7: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_8: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_9: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_10: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_11: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_12: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_13: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_14: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_15: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_16: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_17: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_18: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_19: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_20: integer (nullable = true)\n",
            " |-- FLAG_DOCUMENT_21: integer (nullable = true)\n",
            " |-- AMT_REQ_CREDIT_BUREAU_HOUR: double (nullable = true)\n",
            " |-- AMT_REQ_CREDIT_BUREAU_DAY: double (nullable = true)\n",
            " |-- AMT_REQ_CREDIT_BUREAU_WEEK: double (nullable = true)\n",
            " |-- AMT_REQ_CREDIT_BUREAU_MON: double (nullable = true)\n",
            " |-- AMT_REQ_CREDIT_BUREAU_QRT: double (nullable = true)\n",
            " |-- AMT_REQ_CREDIT_BUREAU_YEAR: double (nullable = true)\n",
            "\n",
            "\n",
            "External data schema:\n",
            "root\n",
            " |-- SK_ID_CURR: integer (nullable = true)\n",
            " |-- EXT_SOURCE_1: double (nullable = true)\n",
            " |-- EXT_SOURCE_2: double (nullable = true)\n",
            " |-- EXT_SOURCE_3: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load data using PySpark\n",
        "df_data = spark.read.csv(\"gcs_internal_data.csv\", header=True, inferSchema=True)\n",
        "df_ext = spark.read.csv(\"gcs_external_sources.csv\", header=True, inferSchema=True)\n",
        "\n",
        "print(f\"Internal data shape: {df_data.count()} rows, {len(df_data.columns)} columns\")\n",
        "print(f\"External data shape: {df_ext.count()} rows, {len(df_ext.columns)} columns\")\n",
        "\n",
        "# Show schema\n",
        "print(\"\\nInternal data schema:\")\n",
        "df_data.printSchema()\n",
        "print(\"\\nExternal data schema:\")\n",
        "df_ext.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wly8dNNbXM9z"
      },
      "source": [
        "## Data Joining\n",
        "Join the datasets on their common identifier key using PySpark DataFrame operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "To29MDl8XM9z",
        "outputId": "08ef0b5e-84db-4010-990e-0745fe3e8356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joined data shape: 307511 rows, 122 columns\n",
            "+----------+------+------------------+-----------+------------+---------------+------------+----------------+----------+-----------+---------------+---------------+----------------+-----------------------------+--------------------+-----------------+--------------------------+----------+-------------+-----------------+---------------+-----------+----------+--------------+---------------+----------------+----------+----------+---------------+---------------+--------------------+---------------------------+--------------------------+-----------------------+--------------------------+--------------------------+---------------------------+----------------------+----------------------+-----------------------+-----------------+--------------+----------------+---------------------------+------------------+--------------+-------------+-------------+-------------+-------------+--------------------+--------------------+--------------+-----------------------+-----------------+---------------+-----------------+----------------------------+----------------+---------------+--------------+--------------+--------------+--------------+-------------+---------------------+---------------+------------------------+------------------+---------------+-----------------+----------------------------+----------------+---------------+--------------+--------------+--------------+--------------+-------------+---------------------+---------------+------------------------+------------------+------------------+--------------+--------------+------------------+-------------------+------------------------+------------------------+------------------------+------------------------+----------------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+--------------------------+-------------------------+--------------------------+-------------------------+-------------------------+--------------------------+------------------+-------------------+------------------+\n",
            "|SK_ID_CURR|TARGET|NAME_CONTRACT_TYPE|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|AMT_CREDIT|AMT_ANNUITY|AMT_GOODS_PRICE|NAME_TYPE_SUITE|NAME_INCOME_TYPE|NAME_EDUCATION_TYPE          |NAME_FAMILY_STATUS  |NAME_HOUSING_TYPE|REGION_POPULATION_RELATIVE|DAYS_BIRTH|DAYS_EMPLOYED|DAYS_REGISTRATION|DAYS_ID_PUBLISH|OWN_CAR_AGE|FLAG_MOBIL|FLAG_EMP_PHONE|FLAG_WORK_PHONE|FLAG_CONT_MOBILE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|REGION_RATING_CLIENT|REGION_RATING_CLIENT_W_CITY|WEEKDAY_APPR_PROCESS_START|HOUR_APPR_PROCESS_START|REG_REGION_NOT_LIVE_REGION|REG_REGION_NOT_WORK_REGION|LIVE_REGION_NOT_WORK_REGION|REG_CITY_NOT_LIVE_CITY|REG_CITY_NOT_WORK_CITY|LIVE_CITY_NOT_WORK_CITY|ORGANIZATION_TYPE|APARTMENTS_AVG|BASEMENTAREA_AVG|YEARS_BEGINEXPLUATATION_AVG|YEARS_BUILD_AVG   |COMMONAREA_AVG|ELEVATORS_AVG|ENTRANCES_AVG|FLOORSMAX_AVG|FLOORSMIN_AVG|LANDAREA_AVG        |LIVINGAPARTMENTS_AVG|LIVINGAREA_AVG|NONLIVINGAPARTMENTS_AVG|NONLIVINGAREA_AVG|APARTMENTS_MODE|BASEMENTAREA_MODE|YEARS_BEGINEXPLUATATION_MODE|YEARS_BUILD_MODE|COMMONAREA_MODE|ELEVATORS_MODE|ENTRANCES_MODE|FLOORSMAX_MODE|FLOORSMIN_MODE|LANDAREA_MODE|LIVINGAPARTMENTS_MODE|LIVINGAREA_MODE|NONLIVINGAPARTMENTS_MODE|NONLIVINGAREA_MODE|APARTMENTS_MEDI|BASEMENTAREA_MEDI|YEARS_BEGINEXPLUATATION_MEDI|YEARS_BUILD_MEDI|COMMONAREA_MEDI|ELEVATORS_MEDI|ENTRANCES_MEDI|FLOORSMAX_MEDI|FLOORSMIN_MEDI|LANDAREA_MEDI|LIVINGAPARTMENTS_MEDI|LIVINGAREA_MEDI|NONLIVINGAPARTMENTS_MEDI|NONLIVINGAREA_MEDI|FONDKAPREMONT_MODE|HOUSETYPE_MODE|TOTALAREA_MODE|WALLSMATERIAL_MODE|EMERGENCYSTATE_MODE|OBS_30_CNT_SOCIAL_CIRCLE|DEF_30_CNT_SOCIAL_CIRCLE|OBS_60_CNT_SOCIAL_CIRCLE|DEF_60_CNT_SOCIAL_CIRCLE|DAYS_LAST_PHONE_CHANGE|FLAG_DOCUMENT_2|FLAG_DOCUMENT_3|FLAG_DOCUMENT_4|FLAG_DOCUMENT_5|FLAG_DOCUMENT_6|FLAG_DOCUMENT_7|FLAG_DOCUMENT_8|FLAG_DOCUMENT_9|FLAG_DOCUMENT_10|FLAG_DOCUMENT_11|FLAG_DOCUMENT_12|FLAG_DOCUMENT_13|FLAG_DOCUMENT_14|FLAG_DOCUMENT_15|FLAG_DOCUMENT_16|FLAG_DOCUMENT_17|FLAG_DOCUMENT_18|FLAG_DOCUMENT_19|FLAG_DOCUMENT_20|FLAG_DOCUMENT_21|AMT_REQ_CREDIT_BUREAU_HOUR|AMT_REQ_CREDIT_BUREAU_DAY|AMT_REQ_CREDIT_BUREAU_WEEK|AMT_REQ_CREDIT_BUREAU_MON|AMT_REQ_CREDIT_BUREAU_QRT|AMT_REQ_CREDIT_BUREAU_YEAR|EXT_SOURCE_1      |EXT_SOURCE_2       |EXT_SOURCE_3      |\n",
            "+----------+------+------------------+-----------+------------+---------------+------------+----------------+----------+-----------+---------------+---------------+----------------+-----------------------------+--------------------+-----------------+--------------------------+----------+-------------+-----------------+---------------+-----------+----------+--------------+---------------+----------------+----------+----------+---------------+---------------+--------------------+---------------------------+--------------------------+-----------------------+--------------------------+--------------------------+---------------------------+----------------------+----------------------+-----------------------+-----------------+--------------+----------------+---------------------------+------------------+--------------+-------------+-------------+-------------+-------------+--------------------+--------------------+--------------+-----------------------+-----------------+---------------+-----------------+----------------------------+----------------+---------------+--------------+--------------+--------------+--------------+-------------+---------------------+---------------+------------------------+------------------+---------------+-----------------+----------------------------+----------------+---------------+--------------+--------------+--------------+--------------+-------------+---------------------+---------------+------------------------+------------------+------------------+--------------+--------------+------------------+-------------------+------------------------+------------------------+------------------------+------------------------+----------------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+--------------------------+-------------------------+--------------------------+-------------------------+-------------------------+--------------------------+------------------+-------------------+------------------+\n",
            "|100003    |0     |Cash loans        |F          |N           |N              |0           |270000.0        |1293502.5 |35698.5    |1129500.0      |Family         |State servant   |Higher education             |Married             |House / apartment|0.003540999999999999      |-16765    |-1188        |-1186.0          |-291           |NULL       |1         |1             |0              |1               |1         |0         |Core staff     |2.0            |1                   |1                          |MONDAY                    |11                     |0                         |0                         |0                          |0                     |0                     |0                      |School           |0.0959        |0.0529          |0.9851                     |0.7959999999999999|0.0605        |0.08         |0.0345       |0.2917       |0.3333       |0.013000000000000001|0.0773              |0.0549        |0.0039                 |0.0098           |0.0924         |0.0538           |0.9851                      |0.804           |0.0497         |0.0806        |0.0345        |0.2917        |0.3333        |0.0128       |0.079                |0.0554         |0.0                     |0.0               |0.0968         |0.0529           |0.9851                      |0.7987          |0.0608         |0.08          |0.0345        |0.2917        |0.3333        |0.0132       |0.0787               |0.0558         |0.0039                  |0.01              |reg oper account  |block of flats|0.0714        |Block             |No                 |1.0                     |0.0                     |1.0                     |0.0                     |-828.0                |0              |1              |0              |0              |0              |0              |0              |0              |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0.0                       |0.0                      |0.0                       |0.0                      |0.0                      |0.0                       |0.3112673113812225|0.6222457752555098 |NULL              |\n",
            "|100007    |0     |Cash loans        |M          |N           |Y              |0           |121500.0        |513000.0  |21865.5    |513000.0       |Unaccompanied  |Working         |Secondary / secondary special|Single / not married|House / apartment|0.028663                  |-19932    |-3038        |-4311.0          |-3458          |NULL       |1         |1             |0              |1               |0         |0         |Core staff     |1.0            |2                   |2                          |THURSDAY                  |11                     |0                         |0                         |0                          |0                     |1                     |1                      |Religion         |NULL          |NULL            |NULL                       |NULL              |NULL          |NULL         |NULL         |NULL         |NULL         |NULL                |NULL                |NULL          |NULL                   |NULL             |NULL           |NULL             |NULL                        |NULL            |NULL           |NULL          |NULL          |NULL          |NULL          |NULL         |NULL                 |NULL           |NULL                    |NULL              |NULL           |NULL             |NULL                        |NULL            |NULL           |NULL          |NULL          |NULL          |NULL          |NULL         |NULL                 |NULL           |NULL                    |NULL              |NULL              |NULL          |NULL          |NULL              |NULL               |0.0                     |0.0                     |0.0                     |0.0                     |-1106.0               |0              |0              |0              |0              |0              |0              |1              |0              |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0.0                       |0.0                      |0.0                       |0.0                      |0.0                      |0.0                       |NULL              |0.3227382869704046 |NULL              |\n",
            "|100008    |0     |Cash loans        |M          |N           |Y              |0           |99000.0         |490495.5  |27517.5    |454500.0       |Spouse, partner|State servant   |Secondary / secondary special|Married             |House / apartment|0.035792000000000004      |-16941    |-1588        |-4970.0          |-477           |NULL       |1         |1             |1              |1               |1         |0         |Laborers       |2.0            |2                   |2                          |WEDNESDAY                 |16                     |0                         |0                         |0                          |0                     |0                     |0                      |Other            |NULL          |NULL            |NULL                       |NULL              |NULL          |NULL         |NULL         |NULL         |NULL         |NULL                |NULL                |NULL          |NULL                   |NULL             |NULL           |NULL             |NULL                        |NULL            |NULL           |NULL          |NULL          |NULL          |NULL          |NULL         |NULL                 |NULL           |NULL                    |NULL              |NULL           |NULL             |NULL                        |NULL            |NULL           |NULL          |NULL          |NULL          |NULL          |NULL         |NULL                 |NULL           |NULL                    |NULL              |NULL              |NULL          |NULL          |NULL              |NULL               |0.0                     |0.0                     |0.0                     |0.0                     |-2536.0               |0              |1              |0              |0              |0              |0              |0              |0              |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0.0                       |0.0                      |0.0                       |0.0                      |1.0                      |1.0                       |NULL              |0.3542247319929012 |0.6212263380626669|\n",
            "|100010    |0     |Cash loans        |M          |Y           |Y              |0           |360000.0        |1530000.0 |42075.0    |1530000.0      |Unaccompanied  |State servant   |Higher education             |Married             |House / apartment|0.003122                  |-18850    |-449         |-4597.0          |-2379          |8.0        |1         |1             |1              |1               |0         |0         |Managers       |2.0            |3                   |3                          |MONDAY                    |16                     |0                         |0                         |0                          |0                     |1                     |1                      |Other            |NULL          |NULL            |NULL                       |NULL              |NULL          |NULL         |NULL         |NULL         |NULL         |NULL                |NULL                |NULL          |NULL                   |NULL             |NULL           |NULL             |NULL                        |NULL            |NULL           |NULL          |NULL          |NULL          |NULL          |NULL         |NULL                 |NULL           |NULL                    |NULL              |NULL           |NULL             |NULL                        |NULL            |NULL           |NULL          |NULL          |NULL          |NULL          |NULL         |NULL                 |NULL           |NULL                    |NULL              |NULL              |NULL          |NULL          |NULL              |NULL               |2.0                     |0.0                     |2.0                     |0.0                     |-1070.0               |0              |1              |0              |0              |0              |0              |0              |0              |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0.0                       |0.0                      |0.0                       |0.0                      |0.0                      |0.0                       |NULL              |0.7142792864482229 |0.5406544504453575|\n",
            "|100011    |0     |Cash loans        |F          |N           |Y              |0           |112500.0        |1019610.0 |33826.5    |913500.0       |Children       |Pensioner       |Secondary / secondary special|Married             |House / apartment|0.018634                  |-20099    |365243       |-7427.0          |-3514          |NULL       |1         |0             |0              |1               |0         |0         |NULL           |2.0            |2                   |2                          |WEDNESDAY                 |14                     |0                         |0                         |0                          |0                     |0                     |0                      |XNA              |NULL          |NULL            |NULL                       |NULL              |NULL          |NULL         |NULL         |NULL         |NULL         |NULL                |NULL                |NULL          |NULL                   |NULL             |NULL           |NULL             |NULL                        |NULL            |NULL           |NULL          |NULL          |NULL          |NULL          |NULL         |NULL                 |NULL           |NULL                    |NULL              |NULL           |NULL             |NULL                        |NULL            |NULL           |NULL          |NULL          |NULL          |NULL          |NULL         |NULL                 |NULL           |NULL                    |NULL              |NULL              |NULL          |NULL          |NULL              |NULL               |1.0                     |0.0                     |1.0                     |0.0                     |0.0                   |0              |1              |0              |0              |0              |0              |0              |0              |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0               |0.0                       |0.0                      |0.0                       |0.0                      |0.0                      |1.0                       |0.5873340468730377|0.20574728800732814|0.7517237147741489|\n",
            "+----------+------+------------------+-----------+------------+---------------+------------+----------------+----------+-----------+---------------+---------------+----------------+-----------------------------+--------------------+-----------------+--------------------------+----------+-------------+-----------------+---------------+-----------+----------+--------------+---------------+----------------+----------+----------+---------------+---------------+--------------------+---------------------------+--------------------------+-----------------------+--------------------------+--------------------------+---------------------------+----------------------+----------------------+-----------------------+-----------------+--------------+----------------+---------------------------+------------------+--------------+-------------+-------------+-------------+-------------+--------------------+--------------------+--------------+-----------------------+-----------------+---------------+-----------------+----------------------------+----------------+---------------+--------------+--------------+--------------+--------------+-------------+---------------------+---------------+------------------------+------------------+---------------+-----------------+----------------------------+----------------+---------------+--------------+--------------+--------------+--------------+-------------+---------------------+---------------+------------------------+------------------+------------------+--------------+--------------+------------------+-------------------+------------------------+------------------------+------------------------+------------------------+----------------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+--------------------------+-------------------------+--------------------------+-------------------------+-------------------------+--------------------------+------------------+-------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Join datasets on SK_ID_CURR (equivalent to pandas merge)\n",
        "df_full = df_data.join(df_ext, on=\"SK_ID_CURR\", how=\"inner\")\n",
        "\n",
        "print(f\"Joined data shape: {df_full.count()} rows, {len(df_full.columns)} columns\")\n",
        "\n",
        "# Show first few rows\n",
        "df_full.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvyixA6jXM90"
      },
      "source": [
        "## Feature Selection\n",
        "Select the same features as in the original implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1Zt3Gr5cXM90",
        "outputId": "3d2c684b-896d-41dc-940f-1690771f45d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features shape: 307511 rows, 18 columns\n",
            "+------------------+------------------+------------------+----------+-------------+-----------------------------+---------------+-----------+-----------+-----------------+---------------+----------+-----------------+----------------------+----------------+----------------+-----------+------+\n",
            "|EXT_SOURCE_1      |EXT_SOURCE_2      |EXT_SOURCE_3      |DAYS_BIRTH|DAYS_EMPLOYED|NAME_EDUCATION_TYPE          |DAYS_ID_PUBLISH|CODE_GENDER|AMT_ANNUITY|DAYS_REGISTRATION|AMT_GOODS_PRICE|AMT_CREDIT|ORGANIZATION_TYPE|DAYS_LAST_PHONE_CHANGE|NAME_INCOME_TYPE|AMT_INCOME_TOTAL|OWN_CAR_AGE|TARGET|\n",
            "+------------------+------------------+------------------+----------+-------------+-----------------------------+---------------+-----------+-----------+-----------------+---------------+----------+-----------------+----------------------+----------------+----------------+-----------+------+\n",
            "|0.3112673113812225|0.6222457752555098|NULL              |-16765    |-1188        |Higher education             |-291           |F          |35698.5    |-1186.0          |1129500.0      |1293502.5 |School           |-828.0                |State servant   |270000.0        |NULL       |0     |\n",
            "|NULL              |0.3227382869704046|NULL              |-19932    |-3038        |Secondary / secondary special|-3458          |M          |21865.5    |-4311.0          |513000.0       |513000.0  |Religion         |-1106.0               |Working         |121500.0        |NULL       |0     |\n",
            "|NULL              |0.3542247319929012|0.6212263380626669|-16941    |-1588        |Secondary / secondary special|-477           |M          |27517.5    |-4970.0          |454500.0       |490495.5  |Other            |-2536.0               |State servant   |99000.0         |NULL       |0     |\n",
            "+------------------+------------------+------------------+----------+-------------+-----------------------------+---------------+-----------+-----------+-----------------+---------------+----------+-----------------+----------------------+----------------+----------------+-----------+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Select the same columns as in the original implementation\n",
        "columns_extract = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
        "                  'DAYS_BIRTH', 'DAYS_EMPLOYED', 'NAME_EDUCATION_TYPE',\n",
        "                  'DAYS_ID_PUBLISH', 'CODE_GENDER', 'AMT_ANNUITY',\n",
        "                  'DAYS_REGISTRATION', 'AMT_GOODS_PRICE', 'AMT_CREDIT',\n",
        "                  'ORGANIZATION_TYPE', 'DAYS_LAST_PHONE_CHANGE',\n",
        "                  'NAME_INCOME_TYPE', 'AMT_INCOME_TOTAL', 'OWN_CAR_AGE', 'TARGET']\n",
        "\n",
        "df = df_full.select(*columns_extract)\n",
        "\n",
        "print(f\"Selected features shape: {df.count()} rows, {len(df.columns)} columns\")\n",
        "df.show(3, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjQRb8VKXM90"
      },
      "source": [
        "## Train-Test Split\n",
        "Split the data into training and testing sets using PySpark's randomSplit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fTXVJgJcXM90",
        "outputId": "be70c952-2ce9-4789-9396-587cb1fa6412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 245885 rows\n",
            "Test set: 61626 rows\n",
            "\n",
            "Training set target distribution:\n",
            "+------+------+\n",
            "|TARGET| count|\n",
            "+------+------+\n",
            "|     1| 19898|\n",
            "|     0|225987|\n",
            "+------+------+\n",
            "\n",
            "Test set target distribution:\n",
            "+------+-----+\n",
            "|TARGET|count|\n",
            "+------+-----+\n",
            "|     1| 4927|\n",
            "|     0|56699|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility (equivalent to np.random.RandomState(101))\n",
        "spark.sparkContext.setCheckpointDir(\"/tmp/spark-checkpoint\")\n",
        "\n",
        "# Split data 80/20 for train/test (equivalent to the original 0.8 split)\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=101)\n",
        "\n",
        "print(f\"Training set: {train_df.count()} rows\")\n",
        "print(f\"Test set: {test_df.count()} rows\")\n",
        "\n",
        "# Check target distribution\n",
        "print(\"\\nTraining set target distribution:\")\n",
        "train_df.groupBy(\"TARGET\").count().show()\n",
        "\n",
        "print(\"Test set target distribution:\")\n",
        "test_df.groupBy(\"TARGET\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5WQy5MbXM90"
      },
      "source": [
        "## Feature Engineering Pipeline\n",
        "Create a PySpark ML Pipeline for preprocessing steps including categorical encoding, imputation, and scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GPUYNUzYXM91",
        "outputId": "9ace2bc7-c8cd-4071-c7bf-8b9982c479d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns: ['NAME_EDUCATION_TYPE', 'CODE_GENDER', 'ORGANIZATION_TYPE', 'NAME_INCOME_TYPE']\n",
            "Numerical columns: ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH', 'AMT_ANNUITY', 'DAYS_REGISTRATION', 'AMT_GOODS_PRICE', 'AMT_CREDIT', 'DAYS_LAST_PHONE_CHANGE', 'AMT_INCOME_TOTAL', 'OWN_CAR_AGE']\n"
          ]
        }
      ],
      "source": [
        "# Identify categorical and numerical columns\n",
        "categorical_cols = ['NAME_EDUCATION_TYPE', 'CODE_GENDER', 'ORGANIZATION_TYPE', 'NAME_INCOME_TYPE']\n",
        "numerical_cols = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
        "                 'DAYS_ID_PUBLISH', 'AMT_ANNUITY', 'DAYS_REGISTRATION', 'AMT_GOODS_PRICE',\n",
        "                 'AMT_CREDIT', 'DAYS_LAST_PHONE_CHANGE', 'AMT_INCOME_TOTAL', 'OWN_CAR_AGE']\n",
        "\n",
        "print(f\"Categorical columns: {categorical_cols}\")\n",
        "print(f\"Numerical columns: {numerical_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Il2hC82HXM91",
        "outputId": "a0fd68ed-b163-4192-b856-2b031ecb8a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created preprocessing pipeline with 11 stages\n"
          ]
        }
      ],
      "source": [
        "# Create preprocessing pipeline stages\n",
        "stages = []\n",
        "\n",
        "# String indexing for categorical variables\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_indexed\", handleInvalid=\"keep\")\n",
        "           for col in categorical_cols]\n",
        "stages.extend(indexers)\n",
        "\n",
        "# One-hot encoding for categorical variables (equivalent to pd.get_dummies)\n",
        "encoders = [OneHotEncoder(inputCol=col + \"_indexed\", outputCol=col + \"_encoded\")\n",
        "           for col in categorical_cols]\n",
        "stages.extend(encoders)\n",
        "\n",
        "# Imputation for numerical columns (median strategy)\n",
        "imputer = Imputer(inputCols=numerical_cols,\n",
        "                 outputCols=[col + \"_imputed\" for col in numerical_cols],\n",
        "                 strategy=\"median\")\n",
        "stages.append(imputer)\n",
        "\n",
        "# Prepare feature columns for vector assembler\n",
        "encoded_categorical_cols = [col + \"_encoded\" for col in categorical_cols]\n",
        "imputed_numerical_cols = [col + \"_imputed\" for col in numerical_cols]\n",
        "feature_cols = encoded_categorical_cols + imputed_numerical_cols\n",
        "\n",
        "# Vector assembler to combine all features\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_unscaled\")\n",
        "stages.append(assembler)\n",
        "\n",
        "# Standard scaling (equivalent to StandardScaler in sklearn)\n",
        "scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\",\n",
        "                       withStd=True, withMean=True)\n",
        "stages.append(scaler)\n",
        "\n",
        "print(f\"Created preprocessing pipeline with {len(stages)} stages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwX6fyZTXM91"
      },
      "source": [
        "## Model Training\n",
        "Train the Random Forest model using PySpark MLlib with the same parameters as the original implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8bcF3o4jXM91",
        "outputId": "3543f68d-ea8d-4d1f-a57e-43098223934b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Model training completed!\n"
          ]
        }
      ],
      "source": [
        "# Random Forest Classifier (equivalent to sklearn RandomForestClassifier)\n",
        "rf = RandomForestClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"TARGET\",\n",
        "    numTrees=100,  # equivalent to n_estimators=100\n",
        "    seed=50,       # equivalent to random_state=50\n",
        "    maxDepth=10,   # reasonable default for large datasets\n",
        "    minInstancesPerNode=1\n",
        ")\n",
        "\n",
        "# Add Random Forest to pipeline\n",
        "stages.append(rf)\n",
        "\n",
        "# Create and fit the complete pipeline\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "print(\"Training the model...\")\n",
        "model = pipeline.fit(train_df)\n",
        "print(\"Model training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b42ZcFmXM91"
      },
      "source": [
        "## Model Evaluation\n",
        "Make predictions and calculate accuracy metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r78RhrG5XM91",
        "outputId": "20775a64-0ee3-4a42-ac40-73f5228882c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+--------------------+\n",
            "|TARGET|prediction|         probability|\n",
            "+------+----------+--------------------+\n",
            "|     0|       0.0|[0.94599076101791...|\n",
            "|     0|       0.0|[0.94812964225961...|\n",
            "|     0|       0.0|[0.95305707500249...|\n",
            "|     0|       0.0|[0.93520617309273...|\n",
            "|     0|       0.0|[0.92914274409465...|\n",
            "|     0|       0.0|[0.94935443193627...|\n",
            "|     0|       0.0|[0.93165552001259...|\n",
            "|     0|       0.0|[0.95327210739395...|\n",
            "|     0|       0.0|[0.91805020378883...|\n",
            "|     0|       0.0|[0.90208553798639...|\n",
            "+------+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "Accuracy: 0.9200499789\n",
            "F1 Score: 0.8817395099\n",
            "AUC: 0.7383602730\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on test set\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# Show predictions\n",
        "predictions.select(\"TARGET\", \"prediction\", \"probability\").show(10)\n",
        "\n",
        "# Calculate accuracy (equivalent to sklearn accuracy_score)\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"TARGET\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"\\nAccuracy: {accuracy:.10f}\")\n",
        "\n",
        "# Additional metrics\n",
        "f1_evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"TARGET\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"f1\"\n",
        ")\n",
        "f1_score = f1_evaluator.evaluate(predictions)\n",
        "print(f\"F1 Score: {f1_score:.10f}\")\n",
        "\n",
        "# AUC for binary classification\n",
        "auc_evaluator = BinaryClassificationEvaluator(\n",
        "    labelCol=\"TARGET\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    metricName=\"areaUnderROC\"\n",
        ")\n",
        "auc = auc_evaluator.evaluate(predictions)\n",
        "print(f\"AUC: {auc:.10f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTReVSxmXM92"
      },
      "source": [
        "## Feature Importance\n",
        "Extract and display feature importance from the trained Random Forest model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5RY_0TUkXM92",
        "outputId": "01c437e5-f274-4971-e37f-72928dba9d98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+\n",
            "|feature_index|          importance|\n",
            "+-------------+--------------------+\n",
            "|           76| 0.22834194769793165|\n",
            "|           75|  0.2166820292029173|\n",
            "|           74| 0.07735218828007503|\n",
            "|           77| 0.05870999204138314|\n",
            "|           82|0.037321662642134164|\n",
            "|           78|0.036841359335253225|\n",
            "|           84|0.030319716821256944|\n",
            "|           83| 0.02801507400550515|\n",
            "|           79|0.027190997161312614|\n",
            "|           80| 0.02678464827943354|\n",
            "|            1|0.025342293583289165|\n",
            "|           81| 0.02279355195552693|\n",
            "|           85|  0.0196588562130137|\n",
            "|           86| 0.01901658236063387|\n",
            "|            5| 0.01615665629476846|\n",
            "|            0|0.015006458808011271|\n",
            "|            6|0.013258105848155686|\n",
            "|           66|0.013134664481939699|\n",
            "|           68|0.008308705163333372|\n",
            "|            9|0.004378737113396536|\n",
            "+-------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "Total number of features after preprocessing: 87\n"
          ]
        }
      ],
      "source": [
        "# Extract the Random Forest model from the pipeline\n",
        "rf_model = model.stages[-1]\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf_model.featureImportances.toArray()\n",
        "\n",
        "# Create feature importance DataFrame with explicit schema\n",
        "# Convert numpy float64 to Python float to avoid schema inference issues\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
        "\n",
        "# Define explicit schema\n",
        "importance_schema = StructType([\n",
        "    StructField(\"feature_index\", IntegerType(), True),\n",
        "    StructField(\"importance\", DoubleType(), True)\n",
        "])\n",
        "\n",
        "# Convert numpy float64 to Python float and create data\n",
        "importance_data = [(int(i), float(importance)) for i, importance in enumerate(feature_importances)]\n",
        "importance_df = spark.createDataFrame(importance_data, schema=importance_schema)\n",
        "\n",
        "# Sort by importance and show top features\n",
        "importance_df.orderBy(col(\"importance\").desc()).show(20)\n",
        "\n",
        "print(f\"\\nTotal number of features after preprocessing: {len(feature_importances)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClawnQwLXM92"
      },
      "source": [
        "## Model Persistence\n",
        "Save the trained model to disk for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GjamqLhuXM92",
        "outputId": "3353b7f4-9bdd-41b4-e47e-cd2c2b8c9c12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: ./pyspark_random_forest_model\n",
            "Random Forest model saved to: ./pyspark_rf_only_model\n"
          ]
        }
      ],
      "source": [
        "# Save the complete pipeline model\n",
        "model_path = \"./pyspark_random_forest_model\"\n",
        "model.write().overwrite().save(model_path)\n",
        "print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "# Also save just the Random Forest model\n",
        "rf_model_path = \"./pyspark_rf_only_model\"\n",
        "rf_model.write().overwrite().save(rf_model_path)\n",
        "print(f\"Random Forest model saved to: {rf_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8hTgnX7XM92"
      },
      "source": [
        "## Question 4.2: Accuracy Metric Analysis\n",
        "\n",
        "### Is accuracy a good choice of metric for this problem?\n",
        "\n",
        "**Answer: No, accuracy is not the best metric for this problem.**\n",
        "\n",
        "**Reasoning:**\n",
        "\n",
        "1. **Class Imbalance**: The dataset shows a severe class imbalance with approximately:\n",
        "   - Class 0 (no default): ~91.9%\n",
        "   - Class 1 (default): ~8.1%\n",
        "\n",
        "2. **Accuracy Paradox**: With such imbalance, a naive classifier that always predicts class 0 would achieve ~91.9% accuracy without learning anything meaningful about the data.\n",
        "\n",
        "3. **Business Context**: In credit risk assessment, the cost of missing a default (false negative) is typically much higher than incorrectly flagging a good customer (false positive). Accuracy treats both errors equally.\n",
        "\n",
        "**Better Metrics for This Problem:**\n",
        "\n",
        "1. **Precision and Recall for Class 1**: Focus on how well we identify actual defaults\n",
        "2. **F1-Score**: Harmonic mean of precision and recall, better for imbalanced datasets\n",
        "3. **AUC-ROC**: Measures the model's ability to distinguish between classes across all thresholds\n",
        "4. **Precision-Recall AUC**: Particularly useful for imbalanced datasets\n",
        "5. **Cost-sensitive metrics**: Incorporate business costs of different types of errors\n",
        "\n",
        "**Conclusion**: While accuracy provides a quick overview, it can be misleading for imbalanced datasets like this credit risk problem. The F1-score and AUC metrics calculated above provide more meaningful insights into model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SpexfJldXM92",
        "outputId": "d186edf6-e514-45a1-f3db-d8f46dc0b637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in test set:\n",
            "Class 1: 4927 samples (8.00%)\n",
            "Class 0: 56699 samples (92.00%)\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate the class imbalance issue\n",
        "print(\"Class distribution in test set:\")\n",
        "# Collect the DataFrame results to convert to Python list for processing\n",
        "class_counts_df = test_df.groupBy(\"TARGET\").count()\n",
        "class_counts = class_counts_df.collect()  # Convert PySpark DataFrame to Python list\n",
        "total_count = test_df.count()\n",
        "\n",
        "for row in class_counts:\n",
        "    class_label = row['TARGET']\n",
        "    count = row['count']\n",
        "    percentage = (count / total_count) * 100\n",
        "    print(f\"Class {class_label}: {count} samples ({percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ScFPGv-3XM93",
        "outputId": "ea9b4b46-8065-4b7f-b4f0-b64fa38d2bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark session stopped.\n"
          ]
        }
      ],
      "source": [
        "# Clean up\n",
        "spark.stop()\n",
        "print(\"Spark session stopped.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}